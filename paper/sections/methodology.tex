% Methodology
% Be specific enough that someone could reproduce your work

\label{sec:methodology}

\subsection{Overview}
Our motivating research question asks how Wikipedia sustains engagement and collective attention without gamified incentive structures. To operationalize this, we analyze patterns of \emph{sustained public attention} across Wikipedia articles using pageview data. Because concepts such as motivation and participation cannot be directly measured, we use pageviews as a quantitative proxy for public engagement.

\subsection{Data Collection}
All data were collected using the Wikimedia Pageviews REST API. Our custom Python script (\texttt{week7.py}) retrieves daily pageview counts for any set of Wikipedia article titles. By default, the script gathers the last 30 full days of pageviews, though custom date windows can also be specified.

For each article, the script collects:
\begin{itemize}
    \item Daily view counts,
    \item Total views over the window, and
    \item Average views per day (a proxy for sustained attention).
\end{itemize}

These values are printed as a comparison table and saved to \texttt{results\_week7.csv} in the project directory for reproducibility.

\subsection{Data Processing}
The data returned by the API are summarized using the \texttt{summarize()} function inside \texttt{week7.py}. This function normalizes the output by calculating:
\begin{itemize}
    \item \texttt{days}: number of valid daily records returned by the API,
    \item \texttt{total}: cumulative pageviews, and
    \item \texttt{avg\_per\_day}: average daily attention to the article.
\end{itemize}

The output CSV and printed table provide a consistent summary format for comparing topics.

\subsection{Proxy and Bridge to Research Question}
Because participation, visibility, and motivation cannot be directly observed, we operationalize engagement using \emph{average daily pageviews}. This serves as a measurable proxy for attention on a platform without algorithmic recommendation or social feedback.

This proxy creates a bridge between our motivating question and our operationalized question: it allows us to quantify how different Wikipedia topics attract and sustain public attention in the absence of likes, follower counts, or algorithmic promotion.

\subsection{Reproducibility}
All code used to collect and process data is included in the \texttt{/src} directory of the repository. The script \texttt{week7.py} can be executed directly to reproduce the results in this paper:

\begin{verbatim}
python week7.py "Artificial intelligence" "Climate change"
\end{verbatim}

All generated data files are saved in the project directory for verification and replication.

